{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Writing popular Machine Learning Optimizers from scratch on Python\n",
    "\n",
    "This blog will include some mathematical and theoritical representation along with Python codes from scratch. Most of the codes and formulas are taken from different resources and i have given links to them also.\n",
    "\n",
    "This post is related to below posts(these posts depends on this post):\n",
    "* [Writing a Feed forward Neural Network from Scratch on Python](https://acharyaramkrishna.com.np/2020/05/31/writing-a-deep-neural-network-from-scratch-on-python/)\n",
    "* [CNN from Scratch](#)\n",
    "\n",
    "# 2. Contains\n",
    "([Optimizers Code were referenced from here.](https://www.github.com/ShivamShrirao/dnn_from_scratch))\n",
    "* Gradient Descent\n",
    "* Momentum\n",
    "* RMS Prop \n",
    "* ADAM\n",
    "* ADAGrad\n",
    "* ADAMAX\n",
    "* ADADelta\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Initialize our class\n",
    "\n",
    "<code>\n",
    "  class Optimizer:\n",
    "    def __init__(self, layers, name=None, learning_rate = 0.01, mr=0.001):\n",
    "        self.name = name\n",
    "        self.learning_rate = learning_rate\n",
    "        self.mr = mr\n",
    "        keys = [\"sgd\", \"iterative\", \"momentum\", \"rmsprop\", \"adagrad\", \"adam\", \"adamax\", \"adadelta\"]\n",
    "        values = [self.sgd, self.iterative, self.momentum, self.rmsprop, self.adagrad, self.adam, self.adamax, self.adadelta]\n",
    "        self.opt_dict = {keys[i]:values[i] for i in range(len(keys))}\n",
    "        if name != None and name in keys:\n",
    "            self.opt_dict[name](layers=layers, training=False)\n",
    "</code>\n",
    "\n",
    "We are using the reference of every optimizer method. The object of this class will be made while compiling the model and at the same time, the reference of the optimizer is taken from the `opt_dict`. The boolean `training` sets all the terms(to 0) that are required for weight optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let me take some notation form the book Tensorflow for Dummies by Matthew Scarpino. Most of the formulas and concepts are taken from this book.\n",
    "* The\tset\tof\ttrainable\tvariables\tis\tdenoted\tŒ∏.\tThe\tvalues\tof\tthe\tvariables\tat Step\tt\tis\tdenoted\tŒ∏t. \n",
    "* The\tloss,\twhich\tis\ta\tmathematical\trelationship\tcontaining\tthe\tmodel‚Äôs variables,\tis\tdenoted\tJ(Œ∏).\tThe\tgradient\tof\tthe\tloss\tis\t‚àáJ(Œ∏). \n",
    "* The\tlearning\trate,\tdenoted\tŒ∑,\tis\ta\tvalue\tthat\taffects\thow\tmuch\tŒ∏j\tchanges from\tstep\tto\tstep.\n",
    "\n",
    "Before diving into algorithm and comparing it with code, let us understand that, i have done addition with all delta terms because i have already taken `minus` of delta terms.\n",
    "\n",
    "## Gradient Descent\n",
    "Weight update term for all units is:-\n",
    "\\begin{equation}\n",
    "\\triangle w_{ji} = \\alpha \\delta_j x_{ji}\n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "\\ when\\ momentum\\ term\\ is\\ applied\\,\n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "\\triangle w_{ji}(n) = \\beta \\delta_j x_{ji} + \\triangle w_{ji}(n-1) \n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "\\ \\beta\\ is\\ momentum\\ rate\n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "\\delta_j\\ formula\\ varies\\ with\\ the\\ unit\\ being\\ output\\ or\\ internal. \n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "w_{ji} = w_{ji} -  \\triangle w_{ji}\\\\\n",
    "\\end{equation}\n",
    "\n",
    "OR more simple representation:-\n",
    "\\begin{equation}\n",
    "\\theta_t = \\theta_t - \\alpha \\triangle J(\\theta)\n",
    "\\end{equation}\n",
    "\n",
    "This\tshows\thow\tthe\tmodel‚Äôs\tvariables\tchange\twith\teach\ttraining\toperation. As\ttraining\tcontinues,\t‚àáJ(Œ∏)\tshould\tapproach\tzero,\twhich\tmeans\tthat\teach new\tset\tof\tvariables\tshould\tbe\tapproximately\tequal\tto\tthe\tprevious\tset.\tAt this\tpoint,\toptimization\thas\tcompleted\tbecause\tthe\toptimizer\thas\tconverged to a minimum. But Gradient Descent always suffers from convergence because the loss might never reach global minimum and oscillate between values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Momentum Optimizer\n",
    "This optimizer tries to eliminate the previous problem of Oscilation between values by introducing momentum term.\n",
    "\\begin{equation}\n",
    "v_t = \\beta v_{t-1} - \\alpha \\triangle J(\\theta)\\\\\n",
    "\\theta = \\theta + v_t\n",
    "\\end{equation}\n",
    "\n",
    "<code>\n",
    "    def momentum(self, layers, learning_rate=0.1, beta1=0.9, weight_decay=0.0005, training=True):\n",
    "        learning_rate = self.learning_rate\n",
    "        for l in layers:\n",
    "            if l.parameters !=0:\n",
    "                if training:\n",
    "                    l.weights_momentum = beta1 * l.weights_momentum + learning_rate * \n",
    "                                         l.delta_weights-weight_decay * learning_rate*l.weights\n",
    "                    l.weights+=l.weights_momentum\n",
    "                    l.biases_momentum = beta1 * l.biases_momentum + learning_rate * \n",
    "                                        l.delta_biases-weight_decay *learning_rate*l.biases\n",
    "                    l.biases+=l.biases_momentum\n",
    "                else:\n",
    "                    l.weights_momentum = 0\n",
    "                    l.biases_momentum = 0\n",
    "</code>\n",
    "\n",
    "The term `weight_decay` and `beta1` is not present on original Momentum Algorithm but it helps to slowly converge the loss towards global minima."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Adagrad\n",
    "* The\tlearning\trate\tchanges\tfrom\tvariable\tto\tvariable\tand\tfrom\tstep\tto\tstep. The\tlearning\trate\tat\tthe\ttth\tstep\tfor\tthe\tith\tvariable\tis\tdenoted\t\t. \n",
    "* Adagrad\tmethods\tcompute\tsubgradients\tinstead\tof\tgradients.\tA subgradient\tis\ta\tgeneralization\tof\ta\tgradient\tthat\tapplies\tto nondifferentiable\tfunctions.\tThis\tmeans\tAdaGrad\tmethods\tcan\toptimize both\tdifferentiable\tand\tnondifferentiable\tfunctions.\n",
    "\n",
    "The learning rate will be:-\n",
    "\\begin{equation}\n",
    "\\alpha_{t,i} = \\frac{\\alpha}{\\sqrt G_{t,ii}}\n",
    "\\end{equation}\n",
    "\n",
    "In\tthis\tequation,\tGt,\tii\tis\tthe\tith\telement\tof\tthe\tdiagonal\tof\tthe\tmatrix\tformed by\ttaking\tthe\touter\tproduct\tof\tthe\tsubgradient\tof\tthe\tloss\twith\titself.\tAfter computing\tthe\tlearning\trates,\tthe\toptimizer\tupdates\tthe\tvariables:\n",
    "\\begin{equation}\n",
    "\\theta_{t,i} = \\theta_{t-1,i} - \\alpha g_t\n",
    "\\end{equation}\n",
    "\n",
    "Shorcoming of this optimizer is that, the learning rate eventually becomes 0 and training stops.\n",
    "\n",
    "<code>\n",
    "    def adagrad(self, layers, learning_rate=0.01, beta1=0.9, epsilon=1e-8, training=True):\n",
    "        learning_rate=self.learning_rate\n",
    "        for l in layers:\n",
    "            if l.parameters != 0:\n",
    "                if training:\n",
    "                    l.weights_adagrad += l.delta_weights ** 2\n",
    "                    l.weights += learning_rate * (l.delta_weights/np.sqrt(l.weights_adagrad+epsilon))\n",
    "                    l.biases_adagrad += l.delta_biases ** 2\n",
    "                    l.biases += learning_rate * (l.delta_biases/np.sqrt(l.biases_adagrad+epsilon))\n",
    "                else:\n",
    "                    l.weights_adagrad = 0\n",
    "                    l.biases_adagrad = 0\n",
    "</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 RMS Prop\n",
    "\n",
    "* This algorithm is devised by Geoffrey Hinton. \n",
    "* This algorithm uses different learning rate for different parameters by using moving average of squared gradient. It utilizes the magnitude of recent gradient to normalize gradient.\n",
    "* Divides learning rate by the average of exponential decay of squared grdients.\n",
    "\n",
    "\\begin{equation}\n",
    "\\theta_{t+1} = \\theta_t - \\frac{\\alpha}{\\sqrt{(1-\\beta) g^2_{t-1} + \\beta g_t + \\epsilon}} * g_t\n",
    "\\end{equation}\n",
    "\n",
    "Where g_t is a delta term for parameter ùúÉ.\n",
    "\n",
    "<code>\n",
    "    def rmsprop(self, layers, learning_rate=0.001, beta1=0.9, epsilon=1e-8, training=True):\n",
    "        learning_rate=self.learning_rate\n",
    "        for l in layers:\n",
    "            if l.parameters !=0:\n",
    "                if training:\n",
    "                    l.weights_rms = beta1*l.weights_rms + (1-beta1)*(l.delta_weights ** 2)\n",
    "                    l.weights += learning_rate * (l.delta_weights/np.sqrt(l.weights_rms + epsilon))\n",
    "                    l.biases_rms = beta1*l.biases_rms + (1-beta1)*(l.delta_biases ** 2)\n",
    "                    l.biases += learning_rate * (l.delta_biases/np.sqrt(l.biases_rms + epsilon))\n",
    "                else:\n",
    "                    l.weights_rms = 0\n",
    "                    l.biases_rms = 0\n",
    "</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 Adam Optimizer\n",
    "The\tAdam\t(Adaptive\tMoment\tEstimation)\talgorithm\tclosely\tresembles\tthe Adagrad\talgorithm\tin\tmany\trespects.\tIt\talso\tresembles\tthe\tMomentum algorithm\tbecause\tit\ttakes\ttwo\tfactors\tinto\taccount:\n",
    "* The\tfirst\tmoment\tvector:\tScales\tthe\tgradient\tby\t`1-beta1`\n",
    "* The\tsecond\tmoment\tvector:\tScales\tthe\tsquare\tof\tthe\tgradient\tby\t`1-beta2`\n",
    "\n",
    "These\tmoment\tvectors\tare\tdenoted\t`mt` and\t`vt`,\trespectively.\t\n",
    "The\tfollowing equations\tshow\thow\ttheir\tvalues\tchange\tfrom\tstep\tto\tstep:\n",
    "\\begin{equation}\n",
    "m_t = \\beta_1 m_{t-1} + (1-\\beta_1) \\triangle J(\\theta)\\\\\n",
    "v_t = \\beta_2 v_{t-1} + (1-\\beta_2)[\\triangle J(\\theta)]^2\\\\\n",
    "m^{\\prime}_t = \\frac{m_t}{1-\\beta^t_1}\\\\\n",
    "v^{\\prime}_t = \\frac{v_t}{1-\\beta^t_2}\\\\\n",
    "\\theta_{t+1} = \\theta_t - \\frac{\\alpha}{\\sqrt{v^{\\prime}_t} + \\epsilon} * m^{\\prime}_t\n",
    "\\end{equation}\n",
    "Where ùúñ is a small value which is used to prevent from divide by 0.\n",
    "\n",
    "<code>\n",
    "    def adam(self, layers, learning_rate=0.001, beta1=0.9, beta2=0.999, epsilon=1e-8, decay=0, training=True):\n",
    "        for l in layers:\n",
    "            if l.parameters != 0:\n",
    "                if training:\n",
    "                    l.t += 1\n",
    "                    if l.t == 1:\n",
    "                        l.pdelta_biases = 0\n",
    "                        l.pdelta_weights = 0\n",
    "                    l.weights_adam1 = beta1 * l.weights_adam1 + (1-beta1)*l.delta_weights\n",
    "                    l.weights_adam2 = beta2 * l.weights_adam2 + (1-beta2)*(l.delta_weights**2)\n",
    "                    mcap = l.weights_adam1/(1-beta1**l.t)\n",
    "                    vcap = l.weights_adam2/(1-beta2**l.t)\n",
    "                    l.delta_weights = mcap/(np.sqrt(vcap) + epsilon)\n",
    "                    l.weights += l.pdelta_weights * self.mr + learning_rate * l.delta_weights\n",
    "                    l.pdelta_weights = l.delta_weights * 0\n",
    "                    l.biases_adam1 = beta1 * l.biases_adam1 + (1-beta1)*l.delta_biases\n",
    "                    l.biases_adam2 = beta2 * l.biases_adam2 + (1-beta2)*(l.delta_biases**2)\n",
    "                    mcap = l.biases_adam1/(1-beta1**l.t)\n",
    "                    vcap = l.biases_adam2/(1-beta2**l.t)\n",
    "                    l.delta_biases = mcap/(np.sqrt(vcap) +epsilon)\n",
    "                    l.biases += l.pdelta_biases * self.mr + learning_rate * l.delta_biases\n",
    "                    l.pdelta_biases = l.delta_biases * 0                    \n",
    "                else:\n",
    "                    l.t = 0\n",
    "                    l.weights_adam1 = 0\n",
    "                    l.weights_adam2 = 0\n",
    "                    l.biases_adam1 = 0\n",
    "                    l.biases_adam2 = 0\n",
    "</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7 Adamax\n",
    "Please refer to the [Sebastian Ruder's site](https://ruder.io) for more explanation.\n",
    "\n",
    "This is slight variation of Adam optimizer.\n",
    "\\begin{equation}\n",
    "u_t = \\beta_2^{\\infty}+ (1-\\beta_2^\\infty) * abs(g_t)^\\infty\\\\\n",
    "\\ = max(\\beta_2 * v_{t-1}, abs(g_t))\\\\\n",
    "\\text now, \\\\ \n",
    "\\theta_{t+1} = \\theta_t - \\frac{\\alpha}{u_t} * m^{\\prime}_t\n",
    "\\end{equation}\n",
    "\n",
    "<code>\n",
    "    def adamax(self, layers, learning_rate=0.002, beta1=0.9, beta2=0.999, epsilon=1e-8, training=True):\n",
    "        for l in layers:\n",
    "            if l.parameters != 0:\n",
    "                if training:\n",
    "                    l.weights_m = beta1*l.weights_m + (1-beta1)*l.delta_weights\n",
    "                    l.weights_v = np.maximum(beta2*l.weights_v, abs(l.delta_weights))\n",
    "                    l.weights += (self.learning_rate/(1-beta1))*(l.weights_m/(l.weights_v+epsilon))                    \n",
    "                    l.biases_m = beta1*l.biases_m + (1-beta1)*l.delta_biases\n",
    "                    l.biases_v = np.maximum(beta2*l.biases_v, abs(l.delta_biases))\n",
    "                    l.biases += (self.learning_rate/(1-beta1))*(l.biases_m/(l.biases_v+epsilon))                    \n",
    "                else:\n",
    "                    l.weights_m = 0\n",
    "                    l.biases_m = 0\n",
    "                    l.weights_v = 0\n",
    "                    l.biases_v = 0\n",
    "</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.8 Adadelta\n",
    "* We don't use learning rate here. But the ratio of the running average of the previous time steps to the current gradient is used.\n",
    "* This algorithm tries to reduce learning rate monotonically. This is extended version of Adagrad.\n",
    "\n",
    "\\begin{equation}\n",
    "\\theta_{t+1} = \\theta_t + \\triangle \\theta_t\\\\\n",
    "\\triangle \\theta = - \\frac{RMS[\\triangle \\theta_t-1]}{RMS[g_t]}.g_t\n",
    "\\end{equation}\n",
    "\n",
    "Where `gt` is the gradient term.\n",
    "\n",
    "<code>\n",
    "    def adadelta(self, layers, learning_rate=0.01, beta1=0.9, epsilon=1e-8, training=True):\n",
    "        for l in layers:\n",
    "            if l.parameters != 0:\n",
    "                if training:\n",
    "                    l.weights_v = beta1*l.weights_v + (1-beta1)*(l.delta_weights ** 2)\n",
    "                    l.delta_weights = np.sqrt((l.weights_m+epsilon)/(l.weights_v+epsilon))*l.delta_weights\n",
    "                    l.weights_m = beta1*l.weights_m + (1-beta1)*(l.delta_weights)\n",
    "                    l.weights += l.delta_weights                    \n",
    "                    l.biases_v = beta1*l.biases_v + (1-beta1)*(l.delta_biases ** 2)\n",
    "                    l.delta_biases = np.sqrt((l.biases_m+epsilon)/(l.biases_v+epsilon))*l.delta_biases\n",
    "                    l.biases_m = beta1*l.biases_m+ (1-beta1)*(l.delta_biases)\n",
    "                    l.biases += l.delta_biases                    \n",
    "                else:\n",
    "                    l.weights_m = 0\n",
    "                    l.biases_m = 0\n",
    "                    l.weights_v = 0\n",
    "                    l.biases_v = 0\n",
    "</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Link to repo\n",
    "* [Please follow this link for the github repo](#)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "* Tensorflow for Dummies by Matthew Scarpino\n",
    "* [Optimizers code were referenced from here](https://www.github.com/ShivamShrirao/dnn_from_scratch)\n",
    "* [An Overview of Gradient Descent Optimization Algorithms](https://ruder.io/optimizing-gradient-descent/index.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
